{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[[ 1.  1.  1. ... -1. -1. -1.]\n",
      " [-1. -1. -1. ... -1. -1. -1.]\n",
      " [-1. -1. -1. ... -1. -1. -1.]\n",
      " ...\n",
      " [-1. -1. -1. ... -1. -1. -1.]\n",
      " [-1. -1. -1. ... -1. -1. -1.]\n",
      " [-1. -1. -1. ... -1. -1. -1.]]\n",
      "epoch 1 updates 1349 16.4 %\n",
      "epoch 2 updates 1194 15.7 %\n",
      "epoch 3 updates 1160 16.3 %\n",
      "epoch 4 updates 1140 16.0 %\n",
      "epoch 5 updates 1123 22.2 %\n",
      "epoch 6 updates 1105 15.4 %\n",
      "epoch 7 updates 1100 15.5 %\n",
      "epoch 8 updates 1090 15.9 %\n",
      "epoch 9 updates 1106 16.1 %\n",
      "epoch 10 updates 1101 21.6 %\n"
     ]
    }
   ],
   "source": [
    "# Basic Perceptron\n",
    "# Reference: https://stackoverflow.com/questions/47213847/how-to-implement-perceptron-in-python\n",
    "\n",
    "from __future__ import division\n",
    "import numpy as np\n",
    "import os\n",
    "# os.chdir(\"/home/minion/Desktop/ML/HW2\")\n",
    "np.random.seed(123)\n",
    "\n",
    "# Need to print the percent positive\n",
    "\n",
    "\n",
    "def perceptron_basic(X, Y, epochs):\n",
    "    ones = np.ones(X.shape[0]).reshape(X.shape[0], 1)  # Creates an array of ones for the bias row.\n",
    "    X1 = np.append(ones, X, axis=1)  # Append the data matrix to the new row of ones.\n",
    "\n",
    "    w = np.zeros(X1.shape[1])  # Create an array of zeros to store the weights.\n",
    "    final_iter = epochs  # Assign final iteration variable to the specified epoch.\n",
    "\n",
    "    for epoch in range(epochs):  # For each epoch until reaching the maximum specified epoch.\n",
    "        misclassified = 0\n",
    "\n",
    "        for i, x in enumerate(X1):  # For each observation and its index in the training set\n",
    "            y = Y[i]  # Store label for the current observation.\n",
    "            predicted_y = np.dot(x, w)  # Calculate the prediction for y.\n",
    "            h = predicted_y*y  # Create a flag to check if the prediction is right.\n",
    "\n",
    "            if h <= 0:  # If prediction is below or equal to zero, then it is wrong.\n",
    "                w = w + x*y  # Update the weight to shift and rotate the plane to be more accurate.\n",
    "                misclassified += 1  # Add 1 to the misclassification counter.\n",
    "            # else: if the prediction is above 0, then it is correct, and we can proceed.\n",
    "        # The process is repeated until all observations have been iterated over, for the requested number of epochs.\n",
    "        if misclassified == 0:  # If we converge, we don't need to continue.\n",
    "            final_iter = epoch\n",
    "            break\n",
    "    updates = misclassified\n",
    "    return w, final_iter, updates  # Return an array of weight and the number of epochs went.\n",
    "\n",
    "\n",
    "def calculate_error_rate(X, Y, w):\n",
    "    ones = np.ones(X.shape[0]).reshape(X.shape[0], 1)  # Creates an array of ones for the bias row.\n",
    "    X1 = np.append(ones, X, axis=1)  # Append the data matrix to the new row of ones.\n",
    "\n",
    "    misclassified = 0\n",
    "\n",
    "    for i, x in enumerate(X1):  # For each observation and its index in the dev set\n",
    "        y = Y[i]  # Store label for the current observation.\n",
    "        predicted_y = np.dot(x, w)  # Calculate the prediction for y.\n",
    "        h = predicted_y * y  # Create a flag to check if the prediction is right.\n",
    "\n",
    "        if h <= 0:  # If prediction is below or equal to zero, then it is wrong.\n",
    "            misclassified += 1  # Add 1 to the misclassification counter.\n",
    "\n",
    "    return misclassified/(X.shape[0])\n",
    "\n",
    "\n",
    "def load_binarized_features(filename, num_rows, num_features):\n",
    "\n",
    "    lines = open(filename).readlines()\n",
    "    lines = [line.strip().split(\", \") for line in lines]\n",
    "    \n",
    "\n",
    "    loaded_data = [[value for idx, value in enumerate(line) if idx not in [9]] for line in lines] #9 is target\n",
    "\n",
    "    # Combining features     \n",
    "    education= [feature for line in lines for i,feature in enumerate(line) if i==2]\n",
    "    sector= [feature for line in lines for i,feature in enumerate(line) if i==4]\n",
    "    loaded_combined_data=[person+[education[i]+'/'+sector[i]] for i,person in enumerate(loaded_data)]\n",
    "    num_of_combined_features=len(set([education[i]+'/'+sector[i] for i,person in enumerate(loaded_data)]))\n",
    "    print(len(loaded_combined_data[0]))\n",
    "       \n",
    "    mapping = {}\n",
    "    new_data = []\n",
    "\n",
    "    for row in loaded_combined_data:\n",
    "        new_row = []\n",
    "        for j, x in enumerate(row):\n",
    "            feature = (j, x)\n",
    "            if feature not in mapping:\n",
    "                mapping[feature] = len(mapping)  # insert a new feature into the index\n",
    "            new_row.append(mapping[feature])\n",
    "        new_data.append(new_row)\n",
    "\n",
    "        \n",
    "    binary_data = -np.ones((num_rows, num_features+num_of_combined_features))\n",
    "    # store normalized numerical values\n",
    "    for idx, row in enumerate(new_data):\n",
    "        for jdx in row:\n",
    "            binary_data[idx][jdx] = 1\n",
    "\n",
    "    return binary_data\n",
    "\n",
    "\n",
    "def load_labels(filename):\n",
    "    lines = open(filename).readlines()\n",
    "    lines = [line.strip().split(\", \") for line in lines]\n",
    "\n",
    "    labels = [[value for idx, value in enumerate(line) if idx in [9]] for line in lines]\n",
    "    labels = [val for sublist in labels for val in sublist]\n",
    "    y_array = []\n",
    "\n",
    "    for label in labels:\n",
    "        if label == '<=50K':\n",
    "            y_array.append(-1)\n",
    "        elif label == '>50K':\n",
    "            y_array.append(1)\n",
    "\n",
    "    y_array = np.array(y_array)\n",
    "    return y_array\n",
    "\n",
    "def main():\n",
    "\n",
    "    filenames = ['income.train.txt.5k', 'income.dev.txt']\n",
    "    with open('combined.txt', 'w') as outfile:\n",
    "        for f in filenames:\n",
    "            with open(f) as infile:\n",
    "                for line in infile:\n",
    "                    outfile.write(line)\n",
    "\n",
    "    filename = 'combined.txt'\n",
    "    num_rows = 6000\n",
    "    num_features = 233 ### WHY?\n",
    "\n",
    "    binarized_features = load_binarized_features(filename, num_rows, num_features)\n",
    "    print(binarized_features)\n",
    "    \n",
    "    xTrain = binarized_features[0:5000]\n",
    "    xDev = binarized_features[5000:6001]\n",
    "\n",
    "    labels = load_labels(filename)\n",
    "\n",
    "    yTrain = np.array(labels[0:5000])\n",
    "    yDev = np.array(labels[5000:6001])\n",
    "\n",
    "\n",
    "    # Fit perceptron\n",
    "    max_epochs = 10\n",
    "    for epoch in range(1, max_epochs+1):\n",
    "        w, final_iter, updates = perceptron_basic(xTrain, yTrain, epoch)\n",
    "        # Calculate error rate\n",
    "        print(\"epoch\", epoch, \"updates\", updates, round(calculate_error_rate(xDev, yDev, w)*100, 2), \"%\")\n",
    "        epoch += 1\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
